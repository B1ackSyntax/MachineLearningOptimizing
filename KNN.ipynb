{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Neareset Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will use the **Digits** data set bundled with *scikit-learn* to implement **K-Neareset Neighbors**.\n",
    "This is a simple machine learning algorithm that is very popular. The *scikit-learn* estimator will use the `fit` method to implement **KNN**. This estimator  will look at the *k-nearest* neighbors to make predictions. It is said to be *lazy* since the work is performed only when used to make predictions. By default **KNN** looks at the five nearest neighbors to make its predictions. The default estimator will be mostly used for simplicity. This notebook will inspect the data, prepare data for fiting, fit the model, and review the results. The end of this example will include **KFolds** and testing multiple models for best accuracy.\n",
    "\n",
    "__[More info on KNN](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)__\n",
    "\n",
    "__[More info on Scikit-Learn](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load_digits returns Bunch object containing the digits and information\n",
    "from sklearn.datasets import load_digits\n",
    "# Load_digits will flatten each 2D array into 1D array\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n"
     ]
    }
   ],
   "source": [
    "# print description of dataset\n",
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the data\n",
    "\n",
    "**It is benificial to inspect the data and become familiar with its details**\n",
    "\n",
    "First we will ensure the dimensions are compatible for the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 1, 7, 4, 8, 2, 2, 4, 4, 1, 9, 7, 3, 2, 1, 2, 5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the target value of every 100th sample\n",
    "digits.target[::100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm the number of samples and features per sample\n",
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm number of targets\n",
    "digits.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can explore our data by using matplotlib visualization toools.** \n",
    "\n",
    "The data array contains 1797 samples, each with 64 features in the range of 1-16, representing the intesity of the pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 600x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "def plot_examples(cms):\n",
    "    \"\"\"\n",
    "    helper function to plot two colormaps\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(6, 3), constrained_layout=True)\n",
    "    for [ax, cmap] in zip(axs, cms):\n",
    "        data = np.random.randn(10, 10)\n",
    "        psm = ax.pcolormesh(data, cmap=cmap, vmin=-1, vmax=16)\n",
    "        fig.colorbar(psm, ax=ax)\n",
    "    plt.show()\n",
    "     \n",
    "g1 = cm.get_cmap('Greys', 16)\n",
    "g2 = cm.get_cmap('gray_r', 16)\n",
    "plot_examples([g1,g2])\n",
    "\n",
    "_,axes = plt.subplots(2, 5,figsize=(7,5))\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for ax, (image, label) in zip(axes[0, :], images_and_labels[:5]):\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    ax.set_title('%i' % label)\n",
    "    ax.set_axis_off()\n",
    "for ax, (image, label) in zip(axes[1, :], images_and_labels[5:10]):\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    ax.set_title('%i' % label)\n",
    "    ax.set_axis_off()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data\n",
    "\n",
    "**We need to split our data for training the model, then testing its precision**\n",
    "\n",
    "Typically data is separated so that we can evaluate the model's performance on data that the model has not seen yet. We will use the sklearn module to split our data randomly. Function **`train_test_split`** will return a tuple of four elementsin which the first two are the *samples* split into training and testing sets, and the last two are the corresponding *training* values split into *training* and *testing sets*. Typically, uppecase **X** is used to represent the *samples*, and lowercase **y** is used ot represent the *targets*. The data has been split into 80% used for *training* and 20% for *testing*. This is achieved by using the heyword argument **`test_size = 0.20`**. The default is 75% for *training* and 25% for *testing*. Using scikit-learn's bundled classification datasets are **balanced**, that is, the samples are divided evenly among the classes. Unbalanced classes can lead to incorrect results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "digits.data, digits.target, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1437, 64) \n",
      "\n",
      "79.97%\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,'\\n')\n",
    "print(f'{X_train.shape[0]/1797:0.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 64) \n",
      "\n",
      "20.03%\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape,'\\n')\n",
    "print(f'{X_test.shape[0]/1797:0.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The KNeighborsClassifier**\n",
    "\n",
    "The next cell will create an object that will implement K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fit` method of **KNN** will be used to on training data sets. The default for k is 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objects for predicted and expected values are created**\n",
    "\n",
    "Using the estimator's predict method with `X_test` as an argument returns an array with the predicted class of each test image\n",
    "\n",
    "`y_test` will be simply renamed for legibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = knn.predict(X=X_test)\n",
    "expected = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results\n",
    "\n",
    "We can now look at the lists of predicted values and expected values then create a list of pairs to compare the resluts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 2, 1, 5, 1, 2, 4, 2, 0, 8, 6, 7, 7, 0, 6, 0, 1, 1, 2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show first 20 predictions\n",
    "predicted[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 2, 1, 5, 1, 2, 4, 2, 0, 8, 6, 7, 7, 0, 6, 0, 1, 1, 2, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show first 20 expectations\n",
    "expected[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally, `List comprehension` and `zip` would be used to create tuples containing the corresponding elements in *predicted* and *expected*. However, the following will create a list of lists with the same corresponding elements. This is so the elements in the list can be easily called when building a comparison visual. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 8], [8, 6], [5, 9], [7, 2], [9, 5], [6, 5], [5, 9], [4, 0]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use list comprehension and zip to build list of wrong predictions\n",
    "wrong = [[p,e] for [p,e] in zip(predicted,expected) if p != e]\n",
    "wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ex = []\n",
    "pred = []\n",
    "# separate the fist 4 values inside of the list of wrong values for visualizatoin\n",
    "if len(wrong)>3:\n",
    "    n = 4\n",
    "else:\n",
    "    n= len(wrong)\n",
    "for i in range(n):\n",
    "    p = wrong[i][0]\n",
    "    e = wrong[i][1]\n",
    "    pred.append((digits.images[p],p))\n",
    "    ex.append((digits.images[e],e))\n",
    "# build image for comparison\n",
    "_,axes = plt.subplots(2, n,figsize=(7, 5))\n",
    "for ax, (image, label) in zip(axes[0, :], pred[:n]):\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    ax.set_title('PREDICTED: %i' % label)\n",
    "    ax.set_axis_off()\n",
    "for ax, (image, label) in zip(axes[1, :], ex[:n]):\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    ax.set_title('EXPECTED: %i' % label)\n",
    "    ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image above shows the first four values the model *predicted* incorrectly and the target value that was expected. The estimator used in this example incorrectly predicted six targets,yet, still achieved an impressive accuracy of 98.33%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.78%\n"
     ]
    }
   ],
   "source": [
    "print(f'{knn.score(X_test,y_test):.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of classification estimators can also be checked by using a **confusion matrix**. This visual will show the correct and incorrect predicted values (sometimes referred to *hits* and *missses*) for a given class. The `y_true` keyword argument specifies the test sample's actual classe. The `y_pred` specifies the predicted digits for those images. The incorrect predictions are shown on the diagonal from top-left to bottom-right. This is known as **principle diagonal**. The non-zero values that are not in the **principle diagonal** indicate incorrect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40,  0,  0,  0,  1,  0,  0,  0,  0,  0],\n",
       "       [ 0, 33,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0, 37,  0,  0,  0,  0,  1,  0,  0],\n",
       "       [ 0,  0,  0, 41,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 41,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 32,  1,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0, 30,  0,  1,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 32,  0,  0],\n",
       "       [ 0,  0,  0,  1,  0,  0,  0,  0, 37,  0],\n",
       "       [ 0,  0,  0,  0,  0,  2,  0,  0,  0, 29]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_true = expected, y_pred = predicted)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sklearn.metrics` module also provides the function `classification_report`. This funciton will produce a table of **classification metrics** based on expected and predicted values. \n",
    "\n",
    "* Precision - total number of correct predicitons for a given digit divided by the total number of predictions for that digit \n",
    "\n",
    "* Recall - total number of correct predictions for a given digit divided by the total number of samples that should have been predicted as that digit\n",
    "\n",
    "* f1-score - The average of the *precision* and *recall*\n",
    "\n",
    "* Support - The number of samples with a given expected value. For exapmle: 50 samples were labeled as 4s, and 38 samples were labeled as 5s\n",
    "\n",
    "More information on those metrics is provided.\n",
    "\n",
    "__[More info on classification metrics](http://scikit-learn.org/stable/modules/model_evaluation.html#precision-recall-and-f-measures)__\n",
    "\n",
    "__[More info on averages in report](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        41\n",
      "           1       1.00      1.00      1.00        33\n",
      "           2       1.00      0.97      0.99        38\n",
      "           3       0.98      1.00      0.99        41\n",
      "           4       0.98      1.00      0.99        41\n",
      "           5       0.94      0.94      0.94        34\n",
      "           6       0.97      0.97      0.97        31\n",
      "           7       0.97      1.00      0.98        32\n",
      "           8       0.97      0.97      0.97        38\n",
      "           9       0.97      0.94      0.95        31\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "names = [str(d) for d in digits.target_names]\n",
    "print(classification_report(expected, predicted, target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `heatmap` from `seaborn` can help improve a confusion matrix by displaying values as colors, with values of higher magnitude displayed as more intense colors. *Seaborn's* graphing functions work with two-dimensional data. Using *Pandas* `pd.DataFrame` will allow *Seaborn* to automatically label its visualizations using the column names and row indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "confusion_df = pd.DataFrame(confusion,\n",
    "                            index=range(10),\n",
    "                            columns=range(10))\n",
    "axes = sns.heatmap(confusion_df,annot=True,\n",
    "                  cmap = 'inferno')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFold Class\n",
    "\n",
    "**K-fold Cross-Validation** enables the use of all of the data for *both* training *and* testing, to give a better sense of how well the model will make predictions for new data by repeatedly trainig and tseting the model with different portions of the dataset. **KFold** splits the dataset into *k* equal-sized *folds* (not related to KNN). The model is then repeatedly trained with *k*-1 folds and tested with the remaining *folds* of the model.\n",
    "\n",
    "For example using **10 Folds**:\n",
    "* 1. Train model with folds 1-9, then test with fold 10\n",
    "* 2. Train model with folds 1-8 and 10, then test with fold 9\n",
    "* 3. Train model with folds 1-7 and 9-10, then test with fold 8\n",
    "* 4. cycle continues until each fold is used\n",
    "\n",
    "`Scikit-learn` provides `KFold` class and `cross_val_score` to help with training and test cycles.\n",
    "\n",
    "* `n_splits = 10` specifies number of Folds\n",
    "\n",
    "* `shuffle = True` causes the KFold object to randomize the data by shuffling it before splitting it into Folds\n",
    "\n",
    "* `estimator=knn` specifies the desired estimator\n",
    "\n",
    "* `X=digits.data` specifies the samples to use for training and testing\n",
    "\n",
    "* `y=digits.target` specifies the target predictions for the samples\n",
    "\n",
    "* `cv=kfold` specifies the cross-validation generator that defines how to split the samples and targets for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits = 10, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98333333, 0.99444444, 1.        , 0.99444444, 0.98888889,\n",
       "       0.97777778, 0.97777778, 0.98324022, 0.97765363, 0.98882682])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(estimator=knn, X=digits.data,\n",
    "                        y=digits.target, cv=kfold)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest accuracy here was 99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 98.66%\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean accuracy: {scores.mean():.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy standard deviation: 0.76%\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy standard deviation: {scores.std():.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average the model was even better than when the model was split 80/20 for training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Best Model\n",
    "\n",
    "It can be very difficult to knwo in advance which model is the best to use for machine-learning. Estimators can be compared to determine which is most accuarate in predictions. There are cost and benifits to each of them. More information can be found below. A loop can be used to execute several models. As the loop passes through items in the estimators dictionary, each key-value pair performs the following:\n",
    "\n",
    "* Unpack the key into `estimator_name` and value into `estimator_object`\n",
    "\n",
    "* Creates a KFold object that shuffles the data and produces 10 folds. The keyword argument `random_state` is important because it ensures that each estimator works with identical folds\n",
    "\n",
    "* Evaluates the current `estimator_object` using `cross_val_score`\n",
    "\n",
    "* Prints the estimator's name, mean and standard deviation of the accuracy scores' computed for each of the 10 folds\n",
    "\n",
    "__[More info on estimators](http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# create estimators\n",
    "estimators = {\n",
    "     'KNeighborsClassifier': knn, \n",
    "     'SVC': SVC(gamma='scale'),\n",
    "     'GaussianNB': GaussianNB()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier: mean accuracy=98.72%; standard deviation=0.75%\n",
      "                 SVC: mean accuracy=98.72%; standard deviation=0.79%\n",
      "          GaussianNB: mean accuracy=84.48%; standard deviation=3.47%\n"
     ]
    }
   ],
   "source": [
    "for estimator_name, estimator_object in estimators.items():\n",
    "    kfold = KFold(n_splits=10, random_state=11, shuffle=True)\n",
    "    scores = cross_val_score(estimator=estimator_object, \n",
    "    X=digits.data, y=digits.target, cv=kfold)\n",
    "    print(f'{estimator_name:>20}: ' + \n",
    "        f'mean accuracy={scores.mean():.2%}; ' +\n",
    "        f'standard deviation={scores.std():.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the results of three models allows easy inspection of accuracy. In this case, **SVC** may be a better model to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
